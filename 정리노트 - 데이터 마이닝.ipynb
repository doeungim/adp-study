{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92f68b84",
   "metadata": {},
   "source": [
    "# 정리노트 - 데이터 마이닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supposed-viewer",
   "metadata": {},
   "source": [
    "### 트레이닝, 테스트 데이터 셋 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f45478",
   "metadata": {},
   "outputs": [],
   "source": [
    "#트레이닝, 테스트 데이터 셋 나누기\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_test_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-singles",
   "metadata": {},
   "source": [
    "### 의사결정나무 (모델평가 포함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608e8839",
   "metadata": {},
   "outputs": [],
   "source": [
    "#의사결정나무\n",
    "#참고 : https://datascienceschool.net/03%20machine%20learning/12.01%20%EC%9D%98%EC%82%AC%EA%B2%B0%EC%A0%95%EB%82%98%EB%AC%B4.html\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "train_accuracy = []\n",
    "predict_accuracy = []\n",
    "depth_range = range(3, 10)\n",
    "for max_depth in depth_range:\n",
    "    model = DecisionTreeClassifier(criterion=\"entropy\", \n",
    "                                   max_depth=max_depth).fit(X_train, y_train)\n",
    "    this_train_acc = accuracy_score(y_train, model.predict(X_train))\n",
    "    this_test_acc = accuracy_score(y_test, model.predict(X_test))\n",
    "    train_accuracy.append(this_train_acc)\n",
    "    predict_accuracy.append(this_test_acc)\n",
    "    auc_score = roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n",
    "    print(\"max_depth : {}\".format(max_depth))\n",
    "    print(\"auc_score : {}\".format(roc_score))\n",
    "    print(\"train_acc - test_acc : {}\".format(this_train_acc - this_test_acc))\n",
    "    print(classification_report(y_test, model.predict(X_test))+\"\\n\\n\")\n",
    "\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.plot(depth_range, train_accuracy, label=\"train_accuracy\")\n",
    "plt.plot(depth_range, predict_accuracy, label=\"predict_accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "maxima_idx = np.argmax(predict_accuracy)\n",
    "print(\"가장 높은 predict_accuracy를 보인 depth : {}\".format(depth_range[maxima_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-samoa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4개 depth를 가진 모델을 가지고 ROC커브로 최적의 threshold를 찾아 정확도를 높여보자.\n",
    "from sklearn.metrics import roc_curve\n",
    "model = DecisionTreeClassifier(criterion=\"entropy\", \n",
    "                               max_depth=4).fit(X_train, y_train)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:,1])\n",
    "roc = pd.DataFrame({\n",
    "    \"FPR\": fpr, \n",
    "    \"TPR\": tpr, \n",
    "    \"Threshold\": thresholds,\n",
    "    \"TPR-FPR\" : tpr-fpr\n",
    "})\n",
    "display(roc)\n",
    "plt.plot(roc[\"FPR\"], roc[\"TPR\"])\n",
    "maxima = np.argmax(roc[\"TPR-FPR\"])\n",
    "print(\"TPR - FPR 최적 threshold값 : {}\".format(roc.iloc[maxima, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-amino",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "custom_threshold = roc.iloc[maxima, 2]\n",
    "pred_proba_flatten = model.predict_proba(X_test)[:,1].reshape(-1,1)\n",
    "binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_flatten) \n",
    "custom_predict = binarizer.transform(pred_proba_flatten)\n",
    "print(\"오리지날\")\n",
    "print(classification_report(y_test, model.predict(X_test))+\"\\n\\n\")\n",
    "\n",
    "print(\"threshold : {}\".format(custom_threshold))\n",
    "print(classification_report(y_test, custom_predict)+\"\\n\\n\")\n",
    "\n",
    "#더 낮아지네???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strange-framing",
   "metadata": {},
   "source": [
    "### 랜덤 포레스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-forge",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# n_estimators : 모델에서 사용할 트리 갯수(학습시 생성할 트리 갯수)\n",
    "# criterion : 분할 품질을 측정하는 기능 (default : gini)\n",
    "# max_depth : 트리의 최대 깊이\n",
    "# min_samples_split : 내부 노드를 분할하는데 필요한 최소 샘플 수 (default : 2)\n",
    "# min_samples_leaf : 리프 노드에 있어야 할 최소 샘플 수 (default : 1)\n",
    "# min_weight_fraction_leaf : \n",
    "#               min_sample_leaf와 같지만 가중치가 부여된 샘플 수에서의 비율\n",
    "# max_features : 각 노드에서 분할에 사용할 특징의 최대 수\n",
    "# max_leaf_nodes : 리프 노드의 최대수\n",
    "# min_impurity_decrease : 최소 불순도\n",
    "# min_impurity_split : 나무 성장을 멈추기 위한 임계치\n",
    "# bootstrap : 부트스트랩(중복허용 샘플링) 사용 여부\n",
    "# oob_score : 일반화 정확도를 줄이기 위해 밖의 샘플 사용 여부\n",
    "# n_jobs :적합성과 예측성을 위해 병렬로 실행할 작업 수\n",
    "# random_state : 난수 seed 설정\n",
    "# verbose : 실행 과정 출력 여부\n",
    "# warm_start : 이전 호출의 솔루션을 재사용하여 합계에 더 많은 견적가를 추가\n",
    "# class_weight : 클래스 가중치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-oriental",
   "metadata": {},
   "outputs": [],
   "source": [
    "#랜덤포레스트\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=500, max_depth=4, \n",
    "                               criterion=\"entropy\", oob_score=True)\n",
    "model.fit(X_train, y_train[\"survived\"])\n",
    "train_acc = accuracy_score(y_train, model.predict(X_train))\n",
    "test_acc = accuracy_score(y_test, model.predict(X_test))\n",
    "auc_score = roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n",
    "\n",
    "print(\"oob_score : {}\".format(model.oob_score_))\n",
    "print(\"train_acc : {}\".format(train_acc))\n",
    "print(\"test_acc : {}\".format(test_acc))\n",
    "print(\"auc_score : {}\".format(roc_score))\n",
    "print(\"train_acc - test_acc : {}\".format(this_train_acc - this_test_acc))\n",
    "print(confusion_matrix(y_test, model.predict(X_test)))\n",
    "print(confusion_matrix(y_test, model.predict(X_test), normalize=\"true\"))\n",
    "print(classification_report(y_test, model.predict(X_test))+\"\\n\\n\")\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:,1])\n",
    "roc = pd.DataFrame({\n",
    "    \"FPR\": fpr, \n",
    "    \"TPR\": tpr, \n",
    "    \"Threshold\": thresholds,\n",
    "    \"TPR-FPR\" : tpr-fpr\n",
    "})\n",
    "display(roc)\n",
    "plt.plot(roc[\"FPR\"], roc[\"TPR\"])\n",
    "maxima = np.argmax(roc[\"TPR-FPR\"])\n",
    "print(\"TPR - FPR 최적 threshold값 : {}\".format(roc.iloc[maxima, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-graduation",
   "metadata": {},
   "source": [
    "### 그라디언트 부스팅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-french",
   "metadata": {},
   "source": [
    "![title](https://github.com/hrdkdh/adp-study/blob/main/images/ensenble.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-estonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model = GradientBoostingClassifier(n_estimators=500)\n",
    "model.fit(X_train, y_train[\"survived\"])\n",
    "\n",
    "train_acc = accuracy_score(y_train, model.predict(X_train))\n",
    "test_acc = accuracy_score(y_test, model.predict(X_test))\n",
    "auc_score = roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n",
    "\n",
    "print(\"train_acc : {}\".format(train_acc))\n",
    "print(\"test_acc : {}\".format(test_acc))\n",
    "print(\"auc_score : {}\".format(roc_score))\n",
    "print(\"train_acc - test_acc : {}\".format(this_train_acc - this_test_acc))\n",
    "print(confusion_matrix(y_test, model.predict(X_test)))\n",
    "print(confusion_matrix(y_test, model.predict(X_test), normalize=\"true\"))\n",
    "print(classification_report(y_test, model.predict(X_test))+\"\\n\\n\")\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:,1])\n",
    "roc = pd.DataFrame({\n",
    "    \"FPR\": fpr, \n",
    "    \"TPR\": tpr, \n",
    "    \"Threshold\": thresholds,\n",
    "    \"TPR-FPR\" : tpr-fpr\n",
    "})\n",
    "display(roc)\n",
    "plt.plot(roc[\"FPR\"], roc[\"TPR\"])\n",
    "maxima = np.argmax(roc[\"TPR-FPR\"])\n",
    "print(\"TPR - FPR 최적 threshold값 : {}\".format(roc.iloc[maxima, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-florida",
   "metadata": {},
   "source": [
    "### k-means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-potter",
   "metadata": {},
   "source": [
    "최적의 군집갯수를 찾는 방법은 엘보우 방법과 실루엣 방법이 있다.<br>\n",
    "엘보우 방법은 군집의 갯수만큼 군집 중심과 군집에 속한 개체들 간의 거리, SSE를 계산해 특정 군집갯수에서 SSE가 확 줄어든다면 그 이전 갯수를 최적의 군집갯수로 정하는 것이다. (팔꿈치가 꺽이는 부분을 최적 갯수로 함(아래 참고)<br><br>\n",
    "k-means 클러스터링은 클러스터내 오차제곱합(SSE)의 값이 최소가 되도록 클러스터의 중심을 결정해나가는 방법이라고 했습니다. 만약 클러스터의 개수를 1로 두고 계산한 SSE 값과, 클러스터의 개수를 2로 두고 계산한 SSE 값을 비교했을 때, 클러스터의 개수를 2로 두고 계산한 SSE 값이 더 작다면, 1개의 클러스터보다 2개의 클러스터가 더 적합하다는 것을 짐작할 수 있습니다.\n",
    "이런 식으로 클러스터의 개수를 늘려나가면서 계산한 SSE를 그래프로 그려봅니다. SSE의 값이 점점 줄어들다가 어느 순간 줄어드는 비율이 급격하게 작아지는 부분이 생기는데, 그래프 모양을 보면 팔꿈치에 해당하는 바로 그 부분이 우리가 구하려는 최적의 클러스터 개수가 됩니다. elbow가 우리말로 팔꿈치라는거 다 아실거고요<br><br>\n",
    "![title](https://raw.githubusercontent.com/hrdkdh/adp-study/main/images/elbow.png)\n",
    "<br><br>\n",
    "실루엣 방법은 한 클러스터 안에 있는 데이터들이 다른 클러스터와 비교해서 얼마나 비슷한가를 나타내는 실루엣 계수를 이용한다.<br>\n",
    "클러스터 안의 거리가 짧을수록 좋고(cohesion, 응집도), 다른 클러스터와의 거리가 멀수록 좋다.(separation, 분리도)<br>\n",
    "아래 그림에서 a는 응집도, b는 분리도이다.<br><br>\n",
    "![title](https://raw.githubusercontent.com/hrdkdh/adp-study/main/images/silhouette.png)<br>\n",
    "실루엣 계수는 -1~1사이의 값을 가지며 1에 가까울수록 잘 부합하는 데이터이다. 실루엣 계수가 0이면 지금클러스터나 다른 클러스터 어디에 있든 상관없음을 의미한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-three",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#엘보우 기법을 사용해 최적 갯수를 찾는다.\n",
    "sse = []\n",
    "cluster_range = range(2, 16)\n",
    "for i in cluster_range:\n",
    "    print(\"{}개로 클러스터링 중...\".format(i), end=\"\\r\")\n",
    "    kmeans = KMeans(n_clusters = i)\n",
    "    kmeans.fit(df3)\n",
    "    sse.append(kmeans.inertia_)\n",
    "print(\"\\n클러스터링 완료\")\n",
    "\n",
    "plt.figure(dpi=200)\n",
    "plt.plot(cluster_range, sse, marker=\"o\")\n",
    "plt.xlabel(\"Cluster n\")\n",
    "plt.xlabel(\"SSE\")\n",
    "plt.show()\n",
    "#대략 6 즈음에서 완만해 지는 듯 하다. 최적 갯수는 6으로 결정!\n",
    "\n",
    "#6개로 다시 클러스터링해 본 다음 중심점을 본다.\n",
    "kmeans = KMeans(n_clusters = 6)\n",
    "kmeans.fit(df3)\n",
    "kmeans.cluster_centers_\n",
    "\n",
    "#라벨링을 한다\n",
    "labels = kmeans.predict(df3)\n",
    "df4 = df3.copy()\n",
    "df4[\"clust\"] = labels\n",
    "df4\n",
    "\n",
    "#각 군집별 레코드의 갯수는?\n",
    "for i in range(0, 6):\n",
    "    print(\"{}번 군집에 속한 레코드의 갯수 : {}\".format(i, \n",
    "                                           len(df4.loc[(df4.clust == i)])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
