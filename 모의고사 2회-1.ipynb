{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90cf040c",
   "metadata": {},
   "source": [
    "### 01. 통계분석\n",
    "\n",
    "##### Admission 데이터 변수의 설명은 아래와 같다.\n",
    "\n",
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>변수</th>\n",
    "            <th>데이터 형태</th>\n",
    "            <th>설명</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>GRE</td>\n",
    "            <td>수치형</td>\n",
    "            <td>GRE점수</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>TOEFL</td>\n",
    "            <td>수치형</td>\n",
    "            <td>TOEFL점수</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Univ_Rating</td>\n",
    "            <td>수치형</td>\n",
    "            <td>대학교 등급점수(1~5 사이의 숫자)</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>SOP</td>\n",
    "            <td>수치형</td>\n",
    "            <td>자기소개서 점수</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>LOR</td>\n",
    "            <td>수치형</td>\n",
    "            <td>추천서 점수</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>CGPA</td>\n",
    "            <td>수치형</td>\n",
    "            <td>평점평균점수</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Research</td>\n",
    "            <td>범주형</td>\n",
    "            <td>연구 실적 유무(0: 없음, 1: 있음)</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Chance_of_Admit</td>\n",
    "            <td>수치형</td>\n",
    "            <td>입학 허가 확률</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a191f391",
   "metadata": {},
   "source": [
    "#### 1) 종속변수인 Chance_of_Admit(입학 허가 확률)와 독립변수(GRE, TOEFL, Univ_Rating, SOP, LOR, CGPA)에 대해 피어슨 상관계수를 이용한 상관관계 분석을 수행하고 그래프를 이용하여 분석결과를 설명하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a122a95c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"data/모의고사 2회/Admission.csv\", encoding=\"utf-8\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d672249",
   "metadata": {},
   "outputs": [],
   "source": [
    "#컬럼 값에 있는 공백 제거\n",
    "new_cols = []\n",
    "for col in df.columns:\n",
    "    new_cols.append(col.strip())\n",
    "\n",
    "df.columns = new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760e5c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#결측치 있는지 체크\n",
    "for col in df.columns:\n",
    "    isna = False\n",
    "    isna_df = df[[col]].isna().query(col+\" == True\")\n",
    "    if len(isna_df) > 0:\n",
    "        isna = True\n",
    "    print(\"{} : {} / len : {}\".format(col, isna, len(isna_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc4e8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#상관계수 산출\n",
    "var_list = []\n",
    "for col in df.columns:\n",
    "    if col != \"Research\":\n",
    "        var_list.append(col)\n",
    "\n",
    "df[var_list].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea46acb3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "#scipy로 상관계수 계산 & 검정\n",
    "for col in var_list:\n",
    "    r = stats.pearsonr(df[\"Chance_of_Admit\"], df[col])\n",
    "    sns.regplot(x=df[col], y=df[\"Chance_of_Admit\"])\n",
    "    plt.show()\n",
    "    print(\"{} - Chance_of_Admit\".format(col))\n",
    "    print(\" └상관계수 : {}, p-value : {}\".format(r[0], r[1]), end=\"\\n\\n\")\n",
    "\n",
    "print(\"모두 양의 상관관계, 검정결과도 적합\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0675ed6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df[var_list], kind=\"reg\", height=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef65ccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "plt.rcParams[\"font.size\"] = 14\n",
    "colormap = plt.cm.PuBu\n",
    "sns.heatmap(df[var_list].corr(), cmap=colormap, annot = True, annot_kws = {\"size\" : 16})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be54df8",
   "metadata": {},
   "source": [
    "#### 2) GRE, TOEFL, Univ_Rating, SOP, LOR, CGPA, Research가 Chance_of_Admit에 영향을 미치는지 알아보는 회귀분석을 단계적 선택법을 사용하여 수행하고 결과를 해석하시오."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529c7d66",
   "metadata": {},
   "source": [
    "참고 : https://no17.tistory.com/195 , https://mindscale.kr/course/basic-stat-python/13/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b263ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import sklearn\n",
    "\n",
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc86597d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg(df, dep_var, ind_vars):\n",
    "    global model\n",
    "    ind_vars_str = \" + \".join(ind_vars)\n",
    "    model = smf.ols(formula=dep_var+\" ~ \"+ind_vars_str, data=df)\n",
    "    print(model.fit().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d087a8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dep_var = \"Chance_of_Admit\"\n",
    "ind_vars = [\"GRE\", \"TOEFL\", \"Univ_Rating\", \"SOP\", \"LOR\", \"CGPA\", \"Research\"]\n",
    "\n",
    "reg(df, dep_var, ind_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5063d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#다중공선성을 계산한다.\n",
    "# print(model.exog_names) #독립변수 리스트 출력\n",
    "factor1_vif = variance_inflation_factor(model.exog, 1) #첫번째 독립변수의 VIF를 계산해 준다.\n",
    "\n",
    "vif_dic = []\n",
    "for i, var in enumerate(model.exog_names):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    this_dic = {\n",
    "        \"독립변수\" : model.exog_names[i],\n",
    "        \"VIF\" : variance_inflation_factor(model.exog, i)\n",
    "    }\n",
    "    vif_dic.append(this_dic)\n",
    "df_vif = pd.DataFrame(vif_dic)\n",
    "display(df_vif)\n",
    "print(\"CGPA의 VIF가 5 이상으로, 다중공선성 주의 필요\")\n",
    "#VIF가 10이 넘으면 다중공선성 있다고 판단하며 5가 넘으면 주의할 필요가 있는 것으로 봅니다.\n",
    "#독립 변수 a와 b가 서로 상관 관계가 있다고 했을 때 두 변수 모두 VIF가 높습니다.\n",
    "#어느 하나만 VIF가 높은 경우는 없습니다.\n",
    "#박수도 오른손과 왼손이 있어야 칠 수 있듯이 서로 연관 있는 변수끼리 VIF가 높습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45701802",
   "metadata": {},
   "outputs": [],
   "source": [
    "#전진 선택법 함수를 만들어 보자 (단계적 선택법도 옵션에 포함)\n",
    "#참고 : https://heejeongchoi.github.io/hydejack/2018-10-23-Supervised-Dimension-Reduction/\n",
    "def forward_selection(df, dep_var, ind_vars, select_criteria = \"AIC\", stepwise=False):\n",
    "    if stepwise:\n",
    "        #후진제거법으로 제거되는 변수를 먼저 찾아 놓는다.\n",
    "        eliminated_vars = backward_elimination(df, dep_var, ind_vars, \"AIC\", \"e\")\n",
    "    candidate_vars = ind_vars.copy()\n",
    "    selected_vars = [] #전진선택법으로 선택된 변수들\n",
    "    alpha = 0.05 #새롭게 편입된 변수의 회귀계수 p-value가 0.05보다 작을 경우에만 선택\n",
    "    \n",
    "    while len(candidate_vars) > 0: #후보 변수 리스트가 모두 소거될 때까지 반복한다.\n",
    "        candidate_vars_reg_result = []\n",
    "        for candidate in candidate_vars:\n",
    "            #새로운 변수가 추가되었을 때 회귀모형의 AIC와 r-square값을 구해본다.\n",
    "            this_ind_vars_str = candidate\n",
    "            if len(selected_vars) > 0:\n",
    "                this_ind_vars_str = \" + \".join(selected_vars) + \" + \" + candidate\n",
    "            this_model_fit = smf.ols(dep_var+\" ~ \"+this_ind_vars_str, data=df).fit()\n",
    "            this_result = {\n",
    "                \"var\" : candidate,\n",
    "                \"AIC\" : this_model_fit.aic,\n",
    "                \"rsquared_adj\" : this_model_fit.rsquared_adj,\n",
    "                \"p-value\" : this_model_fit.pvalues[candidate]\n",
    "            }\n",
    "            candidate_vars_reg_result.append(this_result)\n",
    "        result = pd.DataFrame(candidate_vars_reg_result)\n",
    "        ascending = True\n",
    "        if select_criteria == \"rsquared_adj\":\n",
    "            ascending = False\n",
    "        result.sort_values(by=select_criteria, ascending=ascending, inplace=True)\n",
    "        selected_var = result.iloc[0,[0]].values[0]\n",
    "        selected_var_pvalue = result.iloc[0,[3]].values[0]\n",
    "        if selected_var_pvalue > alpha:\n",
    "            break\n",
    "        selected_vars.append(selected_var)\n",
    "        candidate_vars.remove(selected_var)\n",
    "        if stepwise:\n",
    "            #selected_vars 중에 eliminated_var에 해당하는 것이 있다면 제거한다\n",
    "            if len(selected_vars) > 2 and len(eliminated_vars) > 0:\n",
    "                for ev in eliminated_vars:\n",
    "                    if ev in selected_vars:\n",
    "                        selected_vars.remove(ev)\n",
    "    print(\"후보 독립변수들 : {}\".format(ind_vars))\n",
    "    if stepwise:\n",
    "        print(\"단계적 선택법 선택변수 : {}\".format(selected_vars))\n",
    "    else:\n",
    "        print(\"전진선택법 선택변수 : {}\".format(selected_vars))\n",
    "    return selected_vars\n",
    "\n",
    "forward_selected_ind_vars = forward_selection(df, dep_var, ind_vars, \"AIC\")\n",
    "\n",
    "forward_selected_ind_vars_str = \" + \".join(forward_selected_ind_vars)\n",
    "model = smf.ols(dep_var+\" ~ \"+forward_selected_ind_vars_str, data=df)\n",
    "model_fit = model.fit()\n",
    "print(model_fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feabf72b",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#후진 제거법 함수를 만들어 보자\n",
    "#참고 : https://heejeongchoi.github.io/hydejack/2018-10-23-Supervised-Dimension-Reduction/\n",
    "def backward_elimination(df, dep_var, ind_vars, select_criteria = \"AIC\", return_case = \"selected_vars\"):\n",
    "    alpha = 0.05\n",
    "    selected_vars = ind_vars.copy()\n",
    "    eliminated_vars = []\n",
    "    done = False\n",
    "    \n",
    "    while done is False:\n",
    "        #step1 : 변수 하나씩을 제외한 n개의 모델을 만들어낸다. (n : 변수 갯수)\n",
    "        model_result_list = []\n",
    "        for var in ind_vars:\n",
    "            var_list = ind_vars.copy()\n",
    "            if len(eliminated_vars)>0:\n",
    "                var_list.remove(eliminated_vars)\n",
    "            var_list.remove(var)\n",
    "            this_ind_vars_str = \" + \".join(var_list)\n",
    "            this_model_fit = smf.ols(dep_var+\" ~ \"+this_ind_vars_str, data=df).fit()\n",
    "            this_result = {\n",
    "                \"selected var\" : this_ind_vars_str,\n",
    "                \"eliminated var\" : var,            \n",
    "                \"AIC\" : this_model_fit.aic,\n",
    "                \"rsquared_adj\" : this_model_fit.rsquared_adj\n",
    "            }\n",
    "            model_result_list.append(this_result)\n",
    "        result = pd.DataFrame(model_result_list)\n",
    "        #step2 : n개 모델들 중 가장 좋은 결과를 보인 모델을 선택하고, 제외 후보 변수를 찾는다.\n",
    "        ascending = True\n",
    "        if select_criteria == \"rsquared_adj\":\n",
    "            ascending = False\n",
    "        result.sort_values(by=select_criteria, ascending=ascending, inplace=True)\n",
    "        candidate_var = result.iloc[0, [1]].values[0]\n",
    "        #step3 : 제외 후보 변수로 fitting하여 p-value를 알아보고 유의하다면 종료한다.\n",
    "        candidate_model_fit = smf.ols(dep_var+\" ~ \"+candidate_var, data=df).fit()\n",
    "        if candidate_model_fit.pvalues[candidate_var] > alpha: #유의하지 않다면\n",
    "            eliminated_vars.append(candidate_var) #제거확정\n",
    "            selected_vars.remove(candidate_var)\n",
    "        else: #유의하다면 종료한다\n",
    "            done = True\n",
    "    if return_case == \"s\":\n",
    "        print(\"후보 독립변수들 : {}\".format(ind_vars))\n",
    "        print(\"후진제거법 선택변수 : {}\".format(selected_vars))\n",
    "        return selected_vars\n",
    "    elif return_case == \"e\":\n",
    "        return eliminated_vars\n",
    "    \n",
    "backward_selected_ind_vars = backward_elimination(df, dep_var, ind_vars, \"AIC\", \"s\")\n",
    "\n",
    "backward_selected_ind_vars_str = \" + \".join(backward_selected_ind_vars)\n",
    "model = smf.ols(dep_var+\" ~ \"+backward_selected_ind_vars_str, data=df)\n",
    "model_fit = model.fit()\n",
    "print(model_fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def88b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "stepwise_selected_ind_vars = forward_selection(df, dep_var, ind_vars, \"AIC\", True)\n",
    "\n",
    "stepwise_selected_ind_vars_str = \" + \".join(stepwise_selected_ind_vars)\n",
    "model = smf.ols(dep_var+\" ~ \"+stepwise_selected_ind_vars_str, data=df)\n",
    "model_fit = model.fit()\n",
    "print(model_fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc335d9",
   "metadata": {},
   "source": [
    "#### 3) 단계 선택법을 사용해 변수를 선택한 후 새롭게 생성한 회귀모형에 대한 잔차분석을 수행하고, 그래프를 활용하여 결과를 해석하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d782f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
