{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25f9adcf",
   "metadata": {},
   "source": [
    "# 정리노트 - 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-destruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "#option1 - 유방암 데이터셋\n",
    "import pandas as pd\n",
    "\n",
    "#데이터 로드\n",
    "df = pd.read_csv(\"data/breastCancer.csv\")\n",
    "df.drop(columns={\"Unnamed: 32\"}, axis=1, inplace=True)\n",
    "df[\"target\"] = 0\n",
    "df.loc[(df.diagnosis == \"M\"), \"target\"] = 1\n",
    "df.loc[(df.diagnosis == \"B\"), \"target\"] = 0\n",
    "df.drop(columns={\"id\", \"diagnosis\"}, axis=1, inplace=True)\n",
    "x_vars = df.columns.to_list()\n",
    "x_vars.remove(\"target\")\n",
    "#전처리는 생략..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-density",
   "metadata": {},
   "outputs": [],
   "source": [
    "#option2 - 타이타닉 데이터셋\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/모의고사 2회/titanic.csv\")\n",
    "df.rename(columns={\"survived\" : \"target\"}, inplace=True)\n",
    "\n",
    "df[\"age\"].fillna(df[\"age\"].median(), inplace=True)\n",
    "df[\"fare\"].fillna(df[\"fare\"].median(), inplace=True)\n",
    "df[\"embarked\"].fillna(df[\"embarked\"].mode()[0], inplace=True)\n",
    "df[\"sex_1\"] = \"\"\n",
    "df[\"embarked_1\"] = \"\"\n",
    "df.loc[(df.sex == \"male\"), \"sex_1\"] = 1\n",
    "df.loc[(df.sex == \"female\"), \"sex_1\"] = 2\n",
    "df.loc[(df.embarked == \"S\"), \"embarked_1\"] = 1\n",
    "df.loc[(df.embarked == \"C\"), \"embarked_1\"] = 2\n",
    "df.loc[(df.embarked == \"Q\"), \"embarked_1\"] = 3\n",
    "\n",
    "x_vars = [\"pclass\", \"sex_1\", \"age\", \"sibsp\", \"parch\", \"fare\", \"embarked_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporate-portfolio",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler  # 표준화 패키지 라이브러리\n",
    "df[x_vars] = StandardScaler().fit_transform(df[x_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-pledge",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(df, test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-percentage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model_fit = model.fit(train_data[x_vars], train_data[\"target\"])\n",
    "coef = model_fit.coef_\n",
    "intercept = model_fit.intercept_[0]\n",
    "coef_r = [{\"X\" : \"intercept\", \n",
    "           \"beta\" : intercept, \n",
    "           \"exp(beta) = odds\" : np.exp(intercept)}]\n",
    "for idx, c in enumerate(coef[0]):\n",
    "    this_dict = {\n",
    "        \"X\" : x_vars[idx],\n",
    "        \"beta\" : c,\n",
    "        \"exp(beta) = odds\" : np.exp(c)\n",
    "    }\n",
    "    if np.exp(c) >= 1:\n",
    "        this_dict[\"opinion\"] = \"유방암 확률을 높이는 요소\"\n",
    "    coef_r.append(this_dict)\n",
    "coef_r = pd.DataFrame(coef_r)\n",
    "# coef_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valid-assembly",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# predict_proba #0번째 열은 0일 확률, 1번째 열은 1일 확률\n",
    "predict_proba = model.predict_proba(test_data[x_vars])\n",
    "acc_score = accuracy_score(test_data[\"target\"], \n",
    "                           model.predict(test_data[x_vars]))\n",
    "recall_score = recall_score(test_data[\"target\"], \n",
    "                            model.predict(test_data[x_vars]))\n",
    "precision_score = precision_score(test_data[\"target\"], \n",
    "                                  model.predict(test_data[x_vars]))\n",
    "confusion_matrix = confusion_matrix(test_data[\"target\"], \n",
    "                                    model.predict(test_data[x_vars]))\n",
    "report = classification_report(test_data[\"target\"], \n",
    "                               model.predict(test_data[x_vars]))\n",
    "print(\"acc_score : {:.2f}, recall_score : {:.2f}, precision_score : {:.2f}\".format(acc_score, recall_score, precision_score))\n",
    "print(confusion_matrix)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-racing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4개 depth를 가진 모델을 가지고 ROC커브로 최적의 threshold를 찾아 정확도를 높여보자.\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "fpr, tpr, thresholds = roc_curve(test_data[\"target\"], \n",
    "                                 model.predict_proba(test_data[x_vars])[:,1])\n",
    "\n",
    "roc = pd.DataFrame({\n",
    "    \"FPR\": fpr, \n",
    "    \"TPR\": tpr, \n",
    "    \"Threshold\": thresholds,\n",
    "    \"TPR-FPR\" : tpr-fpr\n",
    "})\n",
    "display(roc)\n",
    "plt.plot(roc[\"FPR\"], roc[\"TPR\"])\n",
    "maxima = np.argmax(roc[\"TPR-FPR\"])\n",
    "print(\"TPR - FPR 최적 threshold값 : {}\".format(roc.iloc[maxima, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-spank",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "custom_threshold = roc.iloc[maxima, 2]\n",
    "pred_proba_flatten = model.predict_proba(test_data[x_vars])[:,1].reshape(-1,1)\n",
    "binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_flatten) \n",
    "custom_predict = binarizer.transform(pred_proba_flatten)\n",
    "print(\"오리지날\")\n",
    "print(classification_report(test_data[\"target\"], \n",
    "                            model.predict(test_data[x_vars]))+\"\\n\\n\")\n",
    "\n",
    "print(\"threshold : {}\".format(custom_threshold))\n",
    "print(classification_report(test_data[\"target\"], custom_predict)+\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
