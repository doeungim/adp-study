{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "encouraging-grove",
   "metadata": {},
   "source": [
    "### 오차행렬과 정밀도/재현율\n",
    "\n",
    "https://velog.io/@ljs7463/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%EB%AA%A8%EB%8D%B8-%ED%8F%89%EA%B0%80%EC%A0%95%EB%B0%80%EB%8F%84%EC%9E%AC%ED%98%84%EC%9C%A8f1-score%EB%93%B1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sixth-thailand",
   "metadata": {},
   "source": [
    "![title](images/confusion_matrix.png)\n",
    "\n",
    "TN : 음성을 음성으로 판별 / 옳은(T) 음성(N) 판별<br>\n",
    "FP : 음성을 양성으로 판별(오류) / 잘못된(F) 양성(P) 판별<br>\n",
    "FN : 양성을 음성으로 판별(오류) / 잘못된(F) 음성(F) 판별<br>\n",
    "TP : 양성을 양성으로 판별 / 옳은(T) 양성(P) 판별<br><br>\n",
    "정밀도(Precision_score) : TP/(FP+TP) --> 내가 양성(P)으로 판명한 것 중에 실제 양성이 있는 비율. 말 그대로 정확도.<br>\n",
    "재현율(recall_score/민감도/TPR) : TP/(FN+TP) --> 실제 양성인 것들 중에 내가 양성(P)으로 얼마나 판별해 냈는가의 비율<br>\n",
    "위양성률(fallout/FPR) : FP/(TN+FP) --> 실제 음성인 것들 중 양성으로 오인, 판별한 것들의 비율<br><br>\n",
    "코로나 검사를 위해 병원을 찾아온 사람의 검사결과는 재현율이 중요하다.<br>\n",
    "실제로 코로나인데 코로나가 아니라고 예측하면 큰일나기 때문이다.<br><br>\n",
    "메일이 왔는데 스팸메일여부를 판단하는 것은 정밀도가 중요하다.<br>\n",
    "스팸으로 판별한 것들 중 스팸이 아닌 것이 섞여 있어도 큰 문제는 없기 때문이다.<br>\n",
    "스팸은 보수적으로 접근해 최대한 많이 걸러내는 게 중요하기 때문이다.<br><br>\n",
    "이렇듯 어떤것에 사용하느냐에 따라 달라지며 대부분은 재현율이 더 중요해 많이 사용하고 있다.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-boxing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y, y_pred)) #정밀도와 재현율 출력\n",
    "print(confusion_matrix(y_test, model.predict(X_test))) #오차행렬 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-jonathan",
   "metadata": {},
   "source": [
    "![title](images/f1_score.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-piece",
   "metadata": {},
   "source": [
    "위 classification_report 결과에서 0이라고 예측한 데이터의 81%만 실제로 0이었고 1이라고 예측한 데이터의 75%만 실제로 1이었음을 알 수 있다. 또한 실제 0인 데이터 중의 84%만 0으로 판별되었고 실제 1인 데이터 중의 71%만 1로 판별되었음을 알 수 있다.<br><br>\n",
    "다중 클래스 문제의 경우에는 각각의 클래스에 대해 자신을 를 양성 클래스로, 다른 클래스를 음성 클래스로 가정하여 OvR 문제를 풀고 각각에 대해 정밀도, 재현율, 위양성률 등의 평가점수를 구한다. 이렇게 하면 클래스별로 각각 다른 평가점수가 나오므로 이를 하나로 합쳐는 일종의 평균을 구해야 하는데 다음과 같은 여러가지 기준을 사용한다.<br><br>\n",
    "accuracy: 정확도. 전체 학습데이터의 개수에서 각 클래스에서 자신의 클래스를 정확하게 맞춘 개수의 비율<br>\n",
    "macro: 단순평균<br>\n",
    "weighted: 각 클래스에 속하는 표본의 갯수로 가중평균<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-sheriff",
   "metadata": {},
   "source": [
    "### F1 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-balloon",
   "metadata": {},
   "source": [
    "F1 Score는 Precision과 Recall의 조화평균으로 주로 분류 클래스 간의 데이터가 불균형이 심각할때 사용한다.<br>\n",
    "F1 Score는 정밀도와 재현율의 조화평균이다.<br><br>\n",
    "F1 Score = precision*recall/precision+recall<br><br>\n",
    "높을수록 좋은 모델이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arabic-gasoline",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subject-music",
   "metadata": {},
   "source": [
    "### ROC Curve와 AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-solution",
   "metadata": {},
   "source": [
    "재현율(recall)과 위양성률(fall-out)은 일반적으로 양의 상관 관계가 있다.<br>\n",
    "재현율을 높이기 위해서는 양성으로 판단하는 기준(threshold)을 낮추어 약간의 증거만 있어도 양성으로 판단하도록 하면 된다. 그러나 이렇게 되면 음성임에도 양성으로 판단되는 표본 데이터가 같이 증가하게 되어 위양성율이 동시에 증가한다. 반대로 위양성율을 낮추기 위해 양성을 판단하는 기준을 엄격하게 두게 되면 증거 부족으로 음성 판단을 받는 표본 데이터의 수가 같이 증가하므로 재현율이 떨어진다.<br>\n",
    "이 기준(threshold)의 최적점을 찾기 위해 사용되는 것이 바로 ROC커브와 AUC이다. (ROC : Receiver Operator Characteristic)<br><br>\n",
    "여기서 말하는 기준, 즉 임계값은 무엇일까?<br>만약 코로나에 걸린 사람을 1 아닌 사람을 0으로 해서 예측을 하는데 있어서 각각의 0과 1은 확률을 가지고 있다. predict(x) 메서드가 아니라 predict_proba(x) 메서드를 쓰면 0과 1로 분류할 확률값을 볼 수 있다. 한 레코드가 0일 확률 0.65, 1일 확률 0.35로 나왔고, 임계치가 0.5로 설정되어 있다면 그 모델은 이 레코드를 0, 음성으로 분류하게 된다. 즉, 임계치는 1(양성)으로 볼 수 있는 기준값이다(양성일 확률에 대한 임계값!). 그런데 이 임계치를 만약 0.3으로 확 낮춰버린다면? 이 레코드의 예측값은 1이 되어 버린다.<br><br>\n",
    "양성 판별 임계값을 0.3으로 두게 되면 양성일 확률 0.35도 1로 예측한다 즉, 코로나 확진으로 모델은 예측하게 된다. 이는 양성판별 기준이 느슨해 진 것이므로(조금만 의심되어도 양성으로 판별하는 것이므로) 재현율(실제 양성인 것들 중 내가 양성으로 판별한 비율값)을 상승시킨다. 하지만 반대로 정밀도(내가 양성이라고 예측한 것들 중 실제로 양성인 것들의 비율값)는 낮아진다. 또한 FPR(위양성률)도 높이게 된다.<br><br>\n",
    "따라서 적절한 임계값을 찾아서 정밀도와 재현율을 효율적으로 만들어야한다. 이때 등장하는것이 ROC-curve와 AUC이다. ROC커브는 X축은 FPR(위양성율), Y축은 TPR(재현율)로 재현한 것이며, AUC는 ROC커브의 면적이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-robert",
   "metadata": {},
   "outputs": [],
   "source": [
    "rom sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_val, y_pred_proba)\n",
    "\n",
    "roc = pd.DataFrame({\n",
    "    'FPR(Fall-out)': fpr, \n",
    "    'TPRate(Recall)': tpr, \n",
    "    'Threshold': thresholds\n",
    "})\n",
    "roc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "provincial-selling",
   "metadata": {},
   "source": [
    "![title](images/roc_matrix.png)\n",
    "![title](images/roc_curve.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-portable",
   "metadata": {},
   "source": [
    "위 그림을 보면 threshold값이 낮아짐에 따라(양성판별 기준이 느슨해짐에 따라) FPR(위양성율)이 증가하고 동시에 TPR(재현율)도 증가하는 것을 볼 수 있다. 그럼 최적점, 즉 최적의 threshold값을 어디에 둬야 할까?<br><br>\n",
    "\n",
    "바로 TPR에서 FPR을 뺀 값이 가장 클 때의 threshold를 찾으면 된다. (TPR - FPR)\n",
    "재현율(실제 양성인데 내가 양성으로 판별한 비율)에서 위양성율(실제 음성인데 내가 양성으로 판별한 비율)을 뺀 값이 가장 클 때, 그 때가 가장 최적점이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-portsmouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold 최대값의 인덱스, np.argmax()\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "print('idx:', optimal_idx, ', threshold:', optimal_threshold)\n",
    "\n",
    "#결과 : idx: 256 , threshold: 0.4633333333333334"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plain-lithuania",
   "metadata": {},
   "source": [
    "AUC값은 ROC곡선 밑의 면적을 구한 것으로, 일반적으로 1에 가까울수록 좋은 수치이고, 0.5에 가까울수록 학습이 제대로 이루어지지 않은 모델을 의미한다. 즉 ROC커브 그래프가 로그함수 모양이면 좋고, 지수함수 모양이면 좋지 않다. AUC가 커지려면 FPR이 작은상태에서 얼마나 큰 TPR을 얻을수 있느냐가 관건이다(=로그함수).즉 가운네 직선에서 멀어지고 왼쪽 상단 모서리쪽으로 가파르게 올라갈 수록 면적이 1에 가까워지는 좋은모델이 된다.<br>\n",
    "AUC는 최적의 threshold를 찾는데 사용되는 것은 아니고, 모델의 성능을 평가하기 위해 사용되는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-genetics",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_score = roc_auc_score(y_test, pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supposed-viewer",
   "metadata": {},
   "source": [
    "### 트레이닝, 테스트 데이터 셋 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f45478",
   "metadata": {},
   "outputs": [],
   "source": [
    "#트레이닝, 테스트 데이터 셋 나누기\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_test_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-singles",
   "metadata": {},
   "source": [
    "### 의사결정나무 (모델평가 포함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608e8839",
   "metadata": {},
   "outputs": [],
   "source": [
    "#의사결정나무\n",
    "#참고 : https://datascienceschool.net/03%20machine%20learning/12.01%20%EC%9D%98%EC%82%AC%EA%B2%B0%EC%A0%95%EB%82%98%EB%AC%B4.html\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "train_accuracy = []\n",
    "predict_accuracy = []\n",
    "depth_range = range(3, 10)\n",
    "for max_depth in depth_range:\n",
    "    model = DecisionTreeClassifier(criterion=\"entropy\", max_depth=max_depth).fit(X_train, y_train)\n",
    "    this_train_acc = accuracy_score(y_train, model.predict(X_train))\n",
    "    this_test_acc = accuracy_score(y_test, model.predict(X_test))\n",
    "    train_accuracy.append(this_train_acc)\n",
    "    predict_accuracy.append(this_test_acc)\n",
    "    auc_score = roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n",
    "    print(\"max_depth : {}\".format(max_depth))\n",
    "    print(\"auc_score : {}\".format(roc_score))\n",
    "    print(\"train_acc - test_acc : {}\".format(this_train_acc - this_test_acc))\n",
    "    print(classification_report(y_test, model.predict(X_test))+\"\\n\\n\")\n",
    "\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.plot(depth_range, train_accuracy, label=\"train_accuracy\")\n",
    "plt.plot(depth_range, predict_accuracy, label=\"predict_accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "maxima_idx = np.argmax(predict_accuracy)\n",
    "print(\"가장 높은 predict_accuracy를 보인 depth : {}\".format(depth_range[maxima_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-samoa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4개 depth를 가진 모델을 가지고 ROC커브로 최적의 threshold를 찾아 정확도를 높여보자.\n",
    "from sklearn.metrics import roc_curve\n",
    "model = DecisionTreeClassifier(criterion=\"entropy\", max_depth=4).fit(X_train, y_train)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:,1])\n",
    "roc = pd.DataFrame({\n",
    "    \"FPR\": fpr, \n",
    "    \"TPR\": tpr, \n",
    "    \"Threshold\": thresholds,\n",
    "    \"TPR-FPR\" : tpr-fpr\n",
    "})\n",
    "display(roc)\n",
    "plt.plot(roc[\"FPR\"], roc[\"TPR\"])\n",
    "maxima = np.argmax(roc[\"TPR-FPR\"])\n",
    "print(\"TPR - FPR 최적 threshold값 : {}\".format(roc.iloc[maxima, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-amino",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "custom_threshold = roc.iloc[maxima, 2]\n",
    "pred_proba_flatten = model.predict_proba(X_test)[:,1].reshape(-1,1)\n",
    "binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_flatten) \n",
    "custom_predict = binarizer.transform(pred_proba_flatten)\n",
    "print(\"오리지날\")\n",
    "print(classification_report(y_test, model.predict(X_test))+\"\\n\\n\")\n",
    "\n",
    "print(\"threshold : {}\".format(custom_threshold))\n",
    "print(classification_report(y_test, custom_predict)+\"\\n\\n\")\n",
    "\n",
    "#더 낮아지네???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strange-framing",
   "metadata": {},
   "source": [
    "### 랜덤 포레스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-forge",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# n_estimators : 모델에서 사용할 트리 갯수(학습시 생성할 트리 갯수)\n",
    "# criterion : 분할 품질을 측정하는 기능 (default : gini)\n",
    "# max_depth : 트리의 최대 깊이\n",
    "# min_samples_split : 내부 노드를 분할하는데 필요한 최소 샘플 수 (default : 2)\n",
    "# min_samples_leaf : 리프 노드에 있어야 할 최소 샘플 수 (default : 1)\n",
    "# min_weight_fraction_leaf : min_sample_leaf와 같지만 가중치가 부여된 샘플 수에서의 비율\n",
    "# max_features : 각 노드에서 분할에 사용할 특징의 최대 수\n",
    "# max_leaf_nodes : 리프 노드의 최대수\n",
    "# min_impurity_decrease : 최소 불순도\n",
    "# min_impurity_split : 나무 성장을 멈추기 위한 임계치\n",
    "# bootstrap : 부트스트랩(중복허용 샘플링) 사용 여부\n",
    "# oob_score : 일반화 정확도를 줄이기 위해 밖의 샘플 사용 여부\n",
    "# n_jobs :적합성과 예측성을 위해 병렬로 실행할 작업 수\n",
    "# random_state : 난수 seed 설정\n",
    "# verbose : 실행 과정 출력 여부\n",
    "# warm_start : 이전 호출의 솔루션을 재사용하여 합계에 더 많은 견적가를 추가\n",
    "# class_weight : 클래스 가중치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-oriental",
   "metadata": {},
   "outputs": [],
   "source": [
    "#랜덤포레스트\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=500, max_depth=4, criterion=\"entropy\", oob_score=True)\n",
    "model.fit(X_train, y_train[\"survived\"])\n",
    "train_acc = accuracy_score(y_train, model.predict(X_train))\n",
    "test_acc = accuracy_score(y_test, model.predict(X_test))\n",
    "auc_score = roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n",
    "\n",
    "print(\"oob_score : {}\".format(model.oob_score_))\n",
    "print(\"train_acc : {}\".format(train_acc))\n",
    "print(\"test_acc : {}\".format(test_acc))\n",
    "print(\"auc_score : {}\".format(roc_score))\n",
    "print(\"train_acc - test_acc : {}\".format(this_train_acc - this_test_acc))\n",
    "print(confusion_matrix(y_test, model.predict(X_test)))\n",
    "print(confusion_matrix(y_test, model.predict(X_test), normalize=\"true\"))\n",
    "print(classification_report(y_test, model.predict(X_test))+\"\\n\\n\")\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:,1])\n",
    "roc = pd.DataFrame({\n",
    "    \"FPR\": fpr, \n",
    "    \"TPR\": tpr, \n",
    "    \"Threshold\": thresholds,\n",
    "    \"TPR-FPR\" : tpr-fpr\n",
    "})\n",
    "display(roc)\n",
    "plt.plot(roc[\"FPR\"], roc[\"TPR\"])\n",
    "maxima = np.argmax(roc[\"TPR-FPR\"])\n",
    "print(\"TPR - FPR 최적 threshold값 : {}\".format(roc.iloc[maxima, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tender-singapore",
   "metadata": {},
   "source": [
    "### 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-argentina",
   "metadata": {},
   "outputs": [],
   "source": [
    "#로지스틱 회귀\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train[\"survived\"])\n",
    "\n",
    "train_acc = accuracy_score(y_train, model.predict(X_train))\n",
    "test_acc = accuracy_score(y_test, model.predict(X_test))\n",
    "auc_score = roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n",
    "\n",
    "print(\"train_acc : {}\".format(train_acc))\n",
    "print(\"test_acc : {}\".format(test_acc))\n",
    "print(\"auc_score : {}\".format(roc_score))\n",
    "print(\"train_acc - test_acc : {}\".format(this_train_acc - this_test_acc))\n",
    "print(confusion_matrix(y_test, model.predict(X_test)))\n",
    "print(confusion_matrix(y_test, model.predict(X_test), normalize=\"true\"))\n",
    "print(classification_report(y_test, model.predict(X_test))+\"\\n\\n\")\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:,1])\n",
    "roc = pd.DataFrame({\n",
    "    \"FPR\": fpr, \n",
    "    \"TPR\": tpr, \n",
    "    \"Threshold\": thresholds,\n",
    "    \"TPR-FPR\" : tpr-fpr\n",
    "})\n",
    "display(roc)\n",
    "plt.plot(roc[\"FPR\"], roc[\"TPR\"])\n",
    "maxima = np.argmax(roc[\"TPR-FPR\"])\n",
    "print(\"TPR - FPR 최적 threshold값 : {}\".format(roc.iloc[maxima, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-graduation",
   "metadata": {},
   "source": [
    "### 그라디언트 부스팅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-french",
   "metadata": {},
   "source": [
    "![title](images/ensenble.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-estonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model = GradientBoostingClassifier(n_estimators=500)\n",
    "model.fit(X_train, y_train[\"survived\"])\n",
    "\n",
    "train_acc = accuracy_score(y_train, model.predict(X_train))\n",
    "test_acc = accuracy_score(y_test, model.predict(X_test))\n",
    "auc_score = roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n",
    "\n",
    "print(\"train_acc : {}\".format(train_acc))\n",
    "print(\"test_acc : {}\".format(test_acc))\n",
    "print(\"auc_score : {}\".format(roc_score))\n",
    "print(\"train_acc - test_acc : {}\".format(this_train_acc - this_test_acc))\n",
    "print(confusion_matrix(y_test, model.predict(X_test)))\n",
    "print(confusion_matrix(y_test, model.predict(X_test), normalize=\"true\"))\n",
    "print(classification_report(y_test, model.predict(X_test))+\"\\n\\n\")\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:,1])\n",
    "roc = pd.DataFrame({\n",
    "    \"FPR\": fpr, \n",
    "    \"TPR\": tpr, \n",
    "    \"Threshold\": thresholds,\n",
    "    \"TPR-FPR\" : tpr-fpr\n",
    "})\n",
    "display(roc)\n",
    "plt.plot(roc[\"FPR\"], roc[\"TPR\"])\n",
    "maxima = np.argmax(roc[\"TPR-FPR\"])\n",
    "print(\"TPR - FPR 최적 threshold값 : {}\".format(roc.iloc[maxima, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-florida",
   "metadata": {},
   "source": [
    "### k-means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-potter",
   "metadata": {},
   "source": [
    "최적의 군집갯수를 찾는 방법은 엘보우 방법과 실루엣 방법이 있다.<br>\n",
    "엘보우 방법은 군집의 갯수만큼 군집 중심과 군집에 속한 개체들 간의 거리, SSE를 계산해 특정 군집갯수에서 SSE가 확 줄어든다면 그 이전 갯수를 최적의 군집갯수로 정하는 것이다. (팔꿈치가 꺽이는 부분을 최적 갯수로 함(아래 참고)<br><br>\n",
    "k-means 클러스터링은 클러스터내 오차제곱합(SSE)의 값이 최소가 되도록 클러스터의 중심을 결정해나가는 방법이라고 했습니다. 만약 클러스터의 개수를 1로 두고 계산한 SSE 값과, 클러스터의 개수를 2로 두고 계산한 SSE 값을 비교했을 때, 클러스터의 개수를 2로 두고 계산한 SSE 값이 더 작다면, 1개의 클러스터보다 2개의 클러스터가 더 적합하다는 것을 짐작할 수 있습니다.\n",
    "이런 식으로 클러스터의 개수를 늘려나가면서 계산한 SSE를 그래프로 그려봅니다. SSE의 값이 점점 줄어들다가 어느 순간 줄어드는 비율이 급격하게 작아지는 부분이 생기는데, 그래프 모양을 보면 팔꿈치에 해당하는 바로 그 부분이 우리가 구하려는 최적의 클러스터 개수가 됩니다. elbow가 우리말로 팔꿈치라는거 다 아실거고요<br><br>\n",
    "![title](images/elbow.png)\n",
    "<br><br>\n",
    "실루엣 방법은 한 클러스터 안에 있는 데이터들이 다른 클러스터와 비교해서 얼마나 비슷한가를 나타내는 실루엣 계수를 이용한다.<br>\n",
    "클러스터 안의 거리가 짧을수록 좋고(cohesion, 응집도), 다른 클러스터와의 거리가 멀수록 좋다.(separation, 분리도)<br>\n",
    "아래 그림에서 a는 응집도, b는 분리도이다.<br><br>\n",
    "![title](images/silhouette.png)<br>\n",
    "실루엣 계수는 -1~1사이의 값을 가지며 1에 가까울수록 잘 부합하는 데이터이다. 실루엣 계수가 0이면 지금클러스터나 다른 클러스터 어디에 있든 상관없음을 의미한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-three",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#엘보우 기법을 사용해 최적 갯수를 찾는다.\n",
    "sse = []\n",
    "cluster_range = range(2, 16)\n",
    "for i in cluster_range:\n",
    "    print(\"{}개로 클러스터링 중...\".format(i), end=\"\\r\")\n",
    "    kmeans = KMeans(n_clusters = i)\n",
    "    kmeans.fit(df3)\n",
    "    sse.append(kmeans.inertia_)\n",
    "print(\"\\n클러스터링 완료\")\n",
    "\n",
    "plt.figure(dpi=200)\n",
    "plt.plot(cluster_range, sse, marker=\"o\")\n",
    "plt.xlabel(\"Cluster n\")\n",
    "plt.xlabel(\"SSE\")\n",
    "plt.show()\n",
    "#대략 6 즈음에서 완만해 지는 듯 하다. 최적 갯수는 6으로 결정!\n",
    "\n",
    "#6개로 다시 클러스터링해 본 다음 중심점을 본다.\n",
    "kmeans = KMeans(n_clusters = 6)\n",
    "kmeans.fit(df3)\n",
    "kmeans.cluster_centers_\n",
    "\n",
    "#라벨링을 한다\n",
    "labels = kmeans.predict(df3)\n",
    "df4 = df3.copy()\n",
    "df4[\"clust\"] = labels\n",
    "df4\n",
    "\n",
    "#각 군집별 레코드의 갯수는?\n",
    "for i in range(0, 6):\n",
    "    print(\"{}번 군집에 속한 레코드의 갯수 : {}\".format(i, len(df4.loc[(df4.clust == i)])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
